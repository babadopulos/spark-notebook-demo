{
  "metadata" : {
    "id" : "6286a73f-8089-4628-9d6e-abd0ed8333eb",
    "name" : "geo-demo",
    "user_save_timestamp" : "1970-01-01T00:00:00.000Z",
    "auto_save_timestamp" : "1970-01-01T00:00:00.000Z",
    "language_info" : {
      "name" : "scala",
      "file_extension" : "scala",
      "codemirror_mode" : "text/x-scala"
    },
    "trusted" : true,
    "sparkNotebook" : null,
    "customLocalRepo" : null,
    "customRepos" : null,
    "customDeps" : [
      "com.amazonaws:aws-java-sdk:1.7.4",
      "org.apache.hadoop:hadoop-aws:2.7.1",
      "com.tailtarget:sparksqlgeohash:1.0-SNAPSHOT"
    ],
    "customImports" : null,
    "customArgs" : null,
    "customSparkConf" : null,
    "customVars" : null
  },
  "cells" : [
    {
      "metadata" : {
        "id" : "5AB597B26A664AEF82399CA66FDEE10E"
      },
      "cell_type" : "markdown",
      "source" : "# Exploration of geo data with Spark SQL"
    },
    {
      "metadata" : {
        "id" : "2164F75E441E432193516707F46716A5"
      },
      "cell_type" : "markdown",
      "source" : "Create the Spark Context:"
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : false,
        "id" : "30B816025CD74DFD8106151D6F3CEAFF"
      },
      "cell_type" : "code",
      "source" : [
        "import org.apache.spark.sql.SparkSession\n",
        "\n",
        "val spark = SparkSession.builder().appName(\"Spark SQL basic example\")\n",
        "                .config(\"dfs.client.use.datanode.hostname\", \"true\")\n",
        "                .config(\"yarn.resourcemanager.address\", \"localhost\").getOrCreate()\n",
        "\n",
        "// This configuration is used to run on docker. If running on the cloud or other server, you can change to:\n",
        "// val spark = SparkSession.builder().appName(\"Spark SQL basic example\").getOrCreate()\n"
      ],
      "outputs" : [
        {
          "name" : "stdout",
          "output_type" : "stream",
          "text" : "import org.apache.spark.sql.SparkSession\nspark: org.apache.spark.sql.SparkSession = org.apache.spark.sql.SparkSession@4e85836a\n"
        },
        {
          "metadata" : { },
          "data" : {
            "text/html" : ""
          },
          "output_type" : "execute_result",
          "execution_count" : 1,
          "time" : "Took: 3.305s, at 2018-06-19 17:59"
        }
      ]
    },
    {
      "metadata" : {
        "id" : "B52CFC4087554101BBBE674328440D63"
      },
      "cell_type" : "markdown",
      "source" : "Read a local data file with geo data and create a Data Frame:"
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : false,
        "id" : "A7566C5166714E78AF3B893996A25ADB"
      },
      "cell_type" : "code",
      "source" : [
        "val df = spark.read.option(\"header\",\"true\").csv(\"/opt/docker/notebooks/spark-sql-demo/example-database.csv\").toDF"
      ],
      "outputs" : [
        {
          "name" : "stdout",
          "output_type" : "stream",
          "text" : "df: org.apache.spark.sql.DataFrame = [id: string, timestamp: string ... 5 more fields]\n"
        },
        {
          "metadata" : { },
          "data" : {
            "text/html" : ""
          },
          "output_type" : "execute_result",
          "execution_count" : 2,
          "time" : "Took: 11.488s, at 2018-06-19 17:59"
        }
      ]
    },
    {
      "metadata" : {
        "id" : "B40E3309870D4FE48DEF48DC0D9ADD2F"
      },
      "cell_type" : "markdown",
      "source" : "Show the data retrieved from the file:"
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : false,
        "id" : "F946B06A3A8949EE80409649F128A929"
      },
      "cell_type" : "code",
      "source" : [
        "df.show"
      ],
      "outputs" : [
        {
          "name" : "stdout",
          "output_type" : "stream",
          "text" : "+--------------------+----------+-------+----------+----------+-------------------+---------+\n|                  id| timestamp|   type|  latitude| longitude|horizontal_accuracy| geo_hash|\n+--------------------+----------+-------+----------+----------+-------------------+---------+\n|d8df62d20b0538ded...|1513324547|android|-12.879151|-38.407512|                8.0|7jswwp2t8|\n|d8df62d20b0538ded...|1514271093|android|-12.879146|-38.407534|                2.0|7jswwp2mx|\n|7730a7ed3612db924...|1514147058|android|-20.729792|-46.609906|               10.0|6uqf5678n|\n|7730a7ed3612db924...|1514147106|android|-20.729728|-46.609985|               10.0|6uqf5678s|\n|7730a7ed3612db924...|1514147387|android|-20.729465| -46.61035|              19.08|6uqf5676h|\n|7730a7ed3612db924...|1514147246|android|-20.729464|-46.610304|             14.595|6uqf5676j|\n|7730a7ed3612db924...|1514147296|android|-20.729458|-46.610304|             12.653|6uqf5676j|\n|7730a7ed3612db924...|1514147201|android|-20.729453|-46.610302|             12.056|6uqf5676j|\n|7730a7ed3612db924...|1514147154|android|-20.729444|-46.610221|             24.859|6uqf5676p|\n|7730a7ed3612db924...|1514147341|android|-20.729381|-46.610312|             18.349|6uqf5676t|\n|7730a7ed3612db924...|1514147013|android|-20.728869|-46.610674|             27.306|6uqf567js|\n|7730a7ed3612db924...|1514146518|android| -20.72774|-46.600174|             12.823|6uqf5ddu1|\n|7730a7ed3612db924...|1513171744|android|-20.727699|-46.600129|              15.44|6uqf5ddu6|\n|7730a7ed3612db924...|1513179926|android|-20.727699|-46.600132|             15.342|6uqf5ddu6|\n|7730a7ed3612db924...|1513159151|android|-20.727697| -46.60013|             15.432|6uqf5ddu6|\n|7730a7ed3612db924...|1513176328|android|-20.727697|-46.600134|              15.29|6uqf5ddu6|\n|7730a7ed3612db924...|1513175408|android|-20.727691|-46.600131|             15.371|6uqf5ddu6|\n|7730a7ed3612db924...|1513160074|android|-20.727688|-46.600139|             15.166|6uqf5ddu6|\n|7730a7ed3612db924...|1513166350|android|-20.727688|-46.600139|             15.253|6uqf5ddu6|\n|7730a7ed3612db924...|1513169010|android|-20.727688|-46.600139|             15.187|6uqf5ddu6|\n+--------------------+----------+-------+----------+----------+-------------------+---------+\nonly showing top 20 rows\n\n"
        },
        {
          "metadata" : { },
          "data" : {
            "text/html" : ""
          },
          "output_type" : "execute_result",
          "execution_count" : 3,
          "time" : "Took: 5.612s, at 2018-06-19 18:00"
        }
      ]
    },
    {
      "metadata" : {
        "id" : "F7C74F841C6C4476B636BA8CC93C48BE"
      },
      "cell_type" : "markdown",
      "source" : "If you want to see the whole columns, show the results like this:"
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : false,
        "id" : "8E2B0A591C8C42D2B4B57387629EF74A"
      },
      "cell_type" : "code",
      "source" : [
        "df.show(false)"
      ],
      "outputs" : [
        {
          "name" : "stdout",
          "output_type" : "stream",
          "text" : "+----------------------------------------+----------+-------+----------+----------+-------------------+---------+\n|id                                      |timestamp |type   |latitude  |longitude |horizontal_accuracy|geo_hash |\n+----------------------------------------+----------+-------+----------+----------+-------------------+---------+\n|d8df62d20b0538dedc173fbab140bbfa3c075e73|1513324547|android|-12.879151|-38.407512|8.0                |7jswwp2t8|\n|d8df62d20b0538dedc173fbab140bbfa3c075e73|1514271093|android|-12.879146|-38.407534|2.0                |7jswwp2mx|\n|7730a7ed3612db92475c748125866f47dfdc00f9|1514147058|android|-20.729792|-46.609906|10.0               |6uqf5678n|\n|7730a7ed3612db92475c748125866f47dfdc00f9|1514147106|android|-20.729728|-46.609985|10.0               |6uqf5678s|\n|7730a7ed3612db92475c748125866f47dfdc00f9|1514147387|android|-20.729465|-46.61035 |19.08              |6uqf5676h|\n|7730a7ed3612db92475c748125866f47dfdc00f9|1514147246|android|-20.729464|-46.610304|14.595             |6uqf5676j|\n|7730a7ed3612db92475c748125866f47dfdc00f9|1514147296|android|-20.729458|-46.610304|12.653             |6uqf5676j|\n|7730a7ed3612db92475c748125866f47dfdc00f9|1514147201|android|-20.729453|-46.610302|12.056             |6uqf5676j|\n|7730a7ed3612db92475c748125866f47dfdc00f9|1514147154|android|-20.729444|-46.610221|24.859             |6uqf5676p|\n|7730a7ed3612db92475c748125866f47dfdc00f9|1514147341|android|-20.729381|-46.610312|18.349             |6uqf5676t|\n|7730a7ed3612db92475c748125866f47dfdc00f9|1514147013|android|-20.728869|-46.610674|27.306             |6uqf567js|\n|7730a7ed3612db92475c748125866f47dfdc00f9|1514146518|android|-20.72774 |-46.600174|12.823             |6uqf5ddu1|\n|7730a7ed3612db92475c748125866f47dfdc00f9|1513171744|android|-20.727699|-46.600129|15.44              |6uqf5ddu6|\n|7730a7ed3612db92475c748125866f47dfdc00f9|1513179926|android|-20.727699|-46.600132|15.342             |6uqf5ddu6|\n|7730a7ed3612db92475c748125866f47dfdc00f9|1513159151|android|-20.727697|-46.60013 |15.432             |6uqf5ddu6|\n|7730a7ed3612db92475c748125866f47dfdc00f9|1513176328|android|-20.727697|-46.600134|15.29              |6uqf5ddu6|\n|7730a7ed3612db92475c748125866f47dfdc00f9|1513175408|android|-20.727691|-46.600131|15.371             |6uqf5ddu6|\n|7730a7ed3612db92475c748125866f47dfdc00f9|1513160074|android|-20.727688|-46.600139|15.166             |6uqf5ddu6|\n|7730a7ed3612db92475c748125866f47dfdc00f9|1513166350|android|-20.727688|-46.600139|15.253             |6uqf5ddu6|\n|7730a7ed3612db92475c748125866f47dfdc00f9|1513169010|android|-20.727688|-46.600139|15.187             |6uqf5ddu6|\n+----------------------------------------+----------+-------+----------+----------+-------------------+---------+\nonly showing top 20 rows\n\n"
        },
        {
          "metadata" : { },
          "data" : {
            "text/html" : ""
          },
          "output_type" : "execute_result",
          "execution_count" : 4,
          "time" : "Took: 4.392s, at 2018-06-19 18:00"
        }
      ]
    },
    {
      "metadata" : {
        "id" : "DA1712C52D254B01B1684F773FDF3C0C"
      },
      "cell_type" : "markdown",
      "source" : "When we read the file, we let Spark SQL to infer the schema in the file. Let's see what it got:"
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : false,
        "id" : "C32A66F7D4CD47258561ADADD0BB4CB5"
      },
      "cell_type" : "code",
      "source" : [
        "df.printSchema"
      ],
      "outputs" : [
        {
          "name" : "stdout",
          "output_type" : "stream",
          "text" : "root\n |-- id: string (nullable = true)\n |-- timestamp: string (nullable = true)\n |-- type: string (nullable = true)\n |-- latitude: string (nullable = true)\n |-- longitude: string (nullable = true)\n |-- horizontal_accuracy: string (nullable = true)\n |-- geo_hash: string (nullable = true)\n\n"
        },
        {
          "metadata" : { },
          "data" : {
            "text/html" : ""
          },
          "output_type" : "execute_result",
          "execution_count" : 5,
          "time" : "Took: 3.033s, at 2018-06-19 18:00"
        }
      ]
    },
    {
      "metadata" : {
        "id" : "DD5864DEBBF340E5AE22A11B25BEA6AB"
      },
      "cell_type" : "markdown",
      "source" : "Note that latitude and longitude were inferred as string, although they are numeric types. To solve this, let's create our own shcema"
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : false,
        "id" : "55E7656E1F2E472D8E37C481A2E61A22"
      },
      "cell_type" : "code",
      "source" : [
        "import org.apache.spark.sql.types._\n",
        "\n",
        "val schema = StructType(Array(\n",
        "    StructField(\"ad_id\",StringType,true),\n",
        "    StructField(\"utc_timestamp\",LongType,true),\n",
        "    StructField(\"id_type\",StringType,true),\n",
        "    StructField(\"latitude\",DoubleType,true),\n",
        "    StructField(\"longitude\",DoubleType,true),\n",
        "    StructField(\"horizontal_accuracy\",DoubleType,true),\n",
        "    StructField(\"geo_hash\",StringType,true)           \n",
        "    )\n",
        ")"
      ],
      "outputs" : [
        {
          "name" : "stdout",
          "output_type" : "stream",
          "text" : "import org.apache.spark.sql.types._\nschema: org.apache.spark.sql.types.StructType = StructType(StructField(ad_id,StringType,true), StructField(utc_timestamp,LongType,true), StructField(id_type,StringType,true), StructField(latitude,DoubleType,true), StructField(longitude,DoubleType,true), StructField(horizontal_accuracy,DoubleType,true), StructField(geo_hash,StringType,true))\n"
        },
        {
          "metadata" : { },
          "data" : {
            "text/html" : ""
          },
          "output_type" : "execute_result",
          "execution_count" : 6,
          "time" : "Took: 2.223s, at 2018-06-19 18:00"
        }
      ]
    },
    {
      "metadata" : {
        "id" : "477D90BFF97B4014920A2ADCCEB5D0E0"
      },
      "cell_type" : "markdown",
      "source" : "And now let's read the file again, but using our schema this time:"
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : false,
        "id" : "A2337BC009B14938834C5B39964E2C8B"
      },
      "cell_type" : "code",
      "source" : [
        "val  records = spark.read.schema(schema).option(\"header\",\"true\").csv(\"/opt/docker/notebooks/spark-sql-demo/example-database.csv\")"
      ],
      "outputs" : [
        {
          "name" : "stdout",
          "output_type" : "stream",
          "text" : "records: org.apache.spark.sql.DataFrame = [ad_id: string, utc_timestamp: bigint ... 5 more fields]\n"
        },
        {
          "metadata" : { },
          "data" : {
            "text/html" : ""
          },
          "output_type" : "execute_result",
          "execution_count" : 7,
          "time" : "Took: 1.929s, at 2018-06-19 18:00"
        }
      ]
    },
    {
      "metadata" : {
        "id" : "DAD0866E5AEF411091300CBEC7D804E2"
      },
      "cell_type" : "markdown",
      "source" : "And let's see how is the schema now:"
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : false,
        "id" : "532F65F4D9B5480EA5FFFFE37C36DDCD"
      },
      "cell_type" : "code",
      "source" : [
        "records.printSchema"
      ],
      "outputs" : [
        {
          "name" : "stdout",
          "output_type" : "stream",
          "text" : "root\n |-- ad_id: string (nullable = true)\n |-- utc_timestamp: long (nullable = true)\n |-- id_type: string (nullable = true)\n |-- latitude: double (nullable = true)\n |-- longitude: double (nullable = true)\n |-- horizontal_accuracy: double (nullable = true)\n |-- geo_hash: string (nullable = true)\n\n"
        },
        {
          "metadata" : { },
          "data" : {
            "text/html" : ""
          },
          "output_type" : "execute_result",
          "execution_count" : 8,
          "time" : "Took: 2.818s, at 2018-06-19 18:00"
        }
      ]
    },
    {
      "metadata" : {
        "id" : "3190A39CB71844D787A8042BD16D2193"
      },
      "cell_type" : "markdown",
      "source" : "And how the data is printed:"
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : false,
        "id" : "9B646E284C314D0D8F5092BDA2B9A963"
      },
      "cell_type" : "code",
      "source" : [
        "records.show()"
      ],
      "outputs" : [
        {
          "name" : "stdout",
          "output_type" : "stream",
          "text" : "+--------------------+-------------+-------+----------+----------+-------------------+---------+\n|               ad_id|utc_timestamp|id_type|  latitude| longitude|horizontal_accuracy| geo_hash|\n+--------------------+-------------+-------+----------+----------+-------------------+---------+\n|d8df62d20b0538ded...|   1513324547|android|-12.879151|-38.407512|                8.0|7jswwp2t8|\n|d8df62d20b0538ded...|   1514271093|android|-12.879146|-38.407534|                2.0|7jswwp2mx|\n|7730a7ed3612db924...|   1514147058|android|-20.729792|-46.609906|               10.0|6uqf5678n|\n|7730a7ed3612db924...|   1514147106|android|-20.729728|-46.609985|               10.0|6uqf5678s|\n|7730a7ed3612db924...|   1514147387|android|-20.729465| -46.61035|              19.08|6uqf5676h|\n|7730a7ed3612db924...|   1514147246|android|-20.729464|-46.610304|             14.595|6uqf5676j|\n|7730a7ed3612db924...|   1514147296|android|-20.729458|-46.610304|             12.653|6uqf5676j|\n|7730a7ed3612db924...|   1514147201|android|-20.729453|-46.610302|             12.056|6uqf5676j|\n|7730a7ed3612db924...|   1514147154|android|-20.729444|-46.610221|             24.859|6uqf5676p|\n|7730a7ed3612db924...|   1514147341|android|-20.729381|-46.610312|             18.349|6uqf5676t|\n|7730a7ed3612db924...|   1514147013|android|-20.728869|-46.610674|             27.306|6uqf567js|\n|7730a7ed3612db924...|   1514146518|android| -20.72774|-46.600174|             12.823|6uqf5ddu1|\n|7730a7ed3612db924...|   1513171744|android|-20.727699|-46.600129|              15.44|6uqf5ddu6|\n|7730a7ed3612db924...|   1513179926|android|-20.727699|-46.600132|             15.342|6uqf5ddu6|\n|7730a7ed3612db924...|   1513159151|android|-20.727697| -46.60013|             15.432|6uqf5ddu6|\n|7730a7ed3612db924...|   1513176328|android|-20.727697|-46.600134|              15.29|6uqf5ddu6|\n|7730a7ed3612db924...|   1513175408|android|-20.727691|-46.600131|             15.371|6uqf5ddu6|\n|7730a7ed3612db924...|   1513160074|android|-20.727688|-46.600139|             15.166|6uqf5ddu6|\n|7730a7ed3612db924...|   1513166350|android|-20.727688|-46.600139|             15.253|6uqf5ddu6|\n|7730a7ed3612db924...|   1513169010|android|-20.727688|-46.600139|             15.187|6uqf5ddu6|\n+--------------------+-------------+-------+----------+----------+-------------------+---------+\nonly showing top 20 rows\n\n"
        },
        {
          "metadata" : { },
          "data" : {
            "text/html" : ""
          },
          "output_type" : "execute_result",
          "execution_count" : 9,
          "time" : "Took: 4.759s, at 2018-06-19 18:00"
        }
      ]
    },
    {
      "metadata" : {
        "id" : "39C1F590D4934A529E5DEB38CE6D0339"
      },
      "cell_type" : "markdown",
      "source" : "We can read data from several other data sources. For example, let's read a file from HDFS:"
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : false,
        "id" : "D16DAE5BA53A4A5A8F4B8160EAE866FF"
      },
      "cell_type" : "code",
      "source" : [
        "val fromHDFS = spark.read.schema(schema).option(\"header\",\"true\")\n",
        "          .csv(\"hdfs://namenode:9000/spark-sql-demo/example-database-on-hdfs.csv\").toDF"
      ],
      "outputs" : [
        {
          "name" : "stdout",
          "output_type" : "stream",
          "text" : "fromHDFS: org.apache.spark.sql.DataFrame = [ad_id: string, utc_timestamp: bigint ... 5 more fields]\n"
        },
        {
          "metadata" : { },
          "data" : {
            "text/html" : ""
          },
          "output_type" : "execute_result",
          "execution_count" : 11,
          "time" : "Took: 1.508s, at 2018-06-19 18:00"
        }
      ]
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : false,
        "id" : "1B29AD282FF6409D81F643C0AD814A95"
      },
      "cell_type" : "code",
      "source" : [
        "fromHDFS.show()"
      ],
      "outputs" : [
        {
          "name" : "stdout",
          "output_type" : "stream",
          "text" : "+--------------------+-------------+-------+----------+----------+-------------------+---------+\n|               ad_id|utc_timestamp|id_type|  latitude| longitude|horizontal_accuracy| geo_hash|\n+--------------------+-------------+-------+----------+----------+-------------------+---------+\n|d8df62d20b0538ded...|   1513324547|android|-12.879151|-38.407512|                8.0|7jswwp2t8|\n|d8df62d20b0538ded...|   1514271093|android|-12.879146|-38.407534|                2.0|7jswwp2mx|\n|7730a7ed3612db924...|   1514147058|android|-20.729792|-46.609906|               10.0|6uqf5678n|\n|7730a7ed3612db924...|   1514147106|android|-20.729728|-46.609985|               10.0|6uqf5678s|\n|7730a7ed3612db924...|   1514147387|android|-20.729465| -46.61035|              19.08|6uqf5676h|\n|7730a7ed3612db924...|   1514147246|android|-20.729464|-46.610304|             14.595|6uqf5676j|\n|7730a7ed3612db924...|   1514147296|android|-20.729458|-46.610304|             12.653|6uqf5676j|\n|7730a7ed3612db924...|   1514147201|android|-20.729453|-46.610302|             12.056|6uqf5676j|\n|7730a7ed3612db924...|   1514147154|android|-20.729444|-46.610221|             24.859|6uqf5676p|\n|7730a7ed3612db924...|   1514147341|android|-20.729381|-46.610312|             18.349|6uqf5676t|\n|7730a7ed3612db924...|   1514147013|android|-20.728869|-46.610674|             27.306|6uqf567js|\n|7730a7ed3612db924...|   1514146518|android| -20.72774|-46.600174|             12.823|6uqf5ddu1|\n|7730a7ed3612db924...|   1513171744|android|-20.727699|-46.600129|              15.44|6uqf5ddu6|\n|7730a7ed3612db924...|   1513179926|android|-20.727699|-46.600132|             15.342|6uqf5ddu6|\n|7730a7ed3612db924...|   1513159151|android|-20.727697| -46.60013|             15.432|6uqf5ddu6|\n|7730a7ed3612db924...|   1513176328|android|-20.727697|-46.600134|              15.29|6uqf5ddu6|\n|7730a7ed3612db924...|   1513175408|android|-20.727691|-46.600131|             15.371|6uqf5ddu6|\n|7730a7ed3612db924...|   1513160074|android|-20.727688|-46.600139|             15.166|6uqf5ddu6|\n|7730a7ed3612db924...|   1513166350|android|-20.727688|-46.600139|             15.253|6uqf5ddu6|\n|7730a7ed3612db924...|   1513169010|android|-20.727688|-46.600139|             15.187|6uqf5ddu6|\n+--------------------+-------------+-------+----------+----------+-------------------+---------+\nonly showing top 20 rows\n\n"
        },
        {
          "metadata" : { },
          "data" : {
            "text/html" : ""
          },
          "output_type" : "execute_result",
          "execution_count" : 12,
          "time" : "Took: 4.604s, at 2018-06-19 18:00"
        }
      ]
    },
    {
      "metadata" : {
        "id" : "F02F032100AD469B8CF70756551273CD"
      },
      "cell_type" : "markdown",
      "source" : "We can also read data from Amazon S3, but in this case we need to use external libraries.\n\nIf you want use external libraries with the spark-shell, you just have to start it this way:\n\nspark-shell --jars /jar/aws-java-sdk-1.7.4.jar,/jar/hadoop-aws-2.7.1.jar\n\nWith notebooks, however, you have to edit the Notebook metadata and add the external dependencies. If they can be retrieved from a Maven repository, the notebook will automatically download it.\n\nTo edit the notebook metadata, go to Edit/Edit Notebook Metadata. Look for the customDeps section and you will see that we already have our dependencies there:\n\n\"customDeps\": [\n    \"com.amazonaws:aws-java-sdk:1.7.4\",\n    \"org.apache.hadoop:hadoop-aws:2.7.1\"\n  ],\n  \nTo read files from a private S3 repository, you need the S3 credentials. A good practice is store the credentials as environment variables, so we don't expose them. Here is how to access external variables:\n\n`val S3_KEY=sys.env(\"S3_KEY\")\n`val S3_SECRET=sys.env(\"S3_SECRET\")\n\nIf you are running on our docker demo, you will notice we read a file at ~/.notebooks/variables.env when starting the notebook (look at the docker/docker-compose.yml file). You can add your environment variables there and use them in the notebook.\n\nNow, let's read the data form S3:\n\n`sc.hadoopConfiguration.set(\"spark.hadoop.fs.s3a.impl\",\"org.apache.hadoop.fs.s3a.S3AFileSystem\")\n`sc.hadoopConfiguration.set(\"fs.s3a.access.key\", S3_KEY)\n`sc.hadoopConfiguration.set(\"fs.s3a.secret.key\", S3_SECRET)\n\n`val csv = spark.read.format(\"com.databricks.spark.csv\").option(\"delimiter\", \" \").load(\"s3a:/temp/geodata.log.gz\")\n\nNote that we can read compressed files and also configure custom delimiters."
    },
    {
      "metadata" : {
        "id" : "46A87087929045B0BBFAB7F5C31A5342"
      },
      "cell_type" : "markdown",
      "source" : "Once we have the data, we can explore it. Let's start by doing a simple select query:"
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : false,
        "id" : "51D83CEF7D8F4347A078BE44D7F0D2EB"
      },
      "cell_type" : "code",
      "source" : [
        "records.filter(\"ad_id = 'd8df62d20b0538dedc173fbab140bbfa3c075e73'\").show(false)"
      ],
      "outputs" : [
        {
          "name" : "stdout",
          "output_type" : "stream",
          "text" : "+----------------------------------------+-------------+-------+----------+----------+-------------------+---------+\n|ad_id                                   |utc_timestamp|id_type|latitude  |longitude |horizontal_accuracy|geo_hash |\n+----------------------------------------+-------------+-------+----------+----------+-------------------+---------+\n|d8df62d20b0538dedc173fbab140bbfa3c075e73|1513324547   |android|-12.879151|-38.407512|8.0                |7jswwp2t8|\n|d8df62d20b0538dedc173fbab140bbfa3c075e73|1514271093   |android|-12.879146|-38.407534|2.0                |7jswwp2mx|\n+----------------------------------------+-------------+-------+----------+----------+-------------------+---------+\n\n"
        },
        {
          "metadata" : { },
          "data" : {
            "text/html" : ""
          },
          "output_type" : "execute_result",
          "execution_count" : 13,
          "time" : "Took: 8.040s, at 2018-06-19 18:00"
        }
      ]
    },
    {
      "metadata" : {
        "id" : "A145500EB60F4C26921AEAF17BD81252"
      },
      "cell_type" : "markdown",
      "source" : "We can also sort data:"
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : false,
        "id" : "9462857F7D334711A95E9B9513D12625"
      },
      "cell_type" : "code",
      "source" : [
        "records.sort(asc(\"ad_id\")).show()"
      ],
      "outputs" : [
        {
          "name" : "stdout",
          "output_type" : "stream",
          "text" : "+--------------------+-------------+-------+----------+----------+-------------------+---------+\n|               ad_id|utc_timestamp|id_type|  latitude| longitude|horizontal_accuracy| geo_hash|\n+--------------------+-------------+-------+----------+----------+-------------------+---------+\n|00046d5b039c98ccc...|   1514336076|android|-23.494881|-46.630882|        17.06299973|6gyf6fukm|\n|00046d5b039c98ccc...|   1514355998|android|-23.494803|-46.630856|        30.29199982|6gyf6fuky|\n|00046d5b039c98ccc...|   1514353745|android| -23.49488|-46.630856|         16.1970005|6gyf6fukq|\n|00046d5b039c98ccc...|   1514312120|android|-23.495479|-46.631469|              200.0|6gyf6fu0b|\n|00046d5b039c98ccc...|   1514353503|android|-23.494876|-46.630843|        17.88199997|6gyf6fukq|\n|00046d5b039c98ccc...|   1514313689|android|-23.495479|-46.631469|              200.0|6gyf6fu0b|\n|00046d5b039c98ccc...|   1514353684|android|-23.494876|-46.630865|        16.33699989|6gyf6fukq|\n|00046d5b039c98ccc...|   1514354219|android|-23.495283|-46.630538|               61.0|6gyf6fudj|\n|00046d5b039c98ccc...|   1514353016|android|-23.494867|-46.630813|        52.10499954|6gyf6fukr|\n|00046d5b039c98ccc...|   1514352529|android|-23.495038|-46.630636|        30.90099907|6gyf6fue7|\n|00046d5b039c98ccc...|   1514355519|android|-23.494867|-46.630819|        31.91500092|6gyf6fukr|\n|00046d5b039c98ccc...|   1514313466|android|-23.494933|-46.631282|        36.07899857|6gyf6fuhh|\n|00046d5b039c98ccc...|   1514335771|android|-23.494859| -46.63086|        27.31699944|6gyf6fukw|\n|00046d5b039c98ccc...|   1514353380|android|-23.494908| -46.63075|        28.29299927|6gyf6fus0|\n|00046d5b039c98ccc...|   1514337703|android| -23.49485|-46.630865|        32.04000092|6gyf6fukw|\n|00046d5b039c98ccc...|   1514353563|android|-23.494897| -46.63079|        33.05799866|6gyf6fukr|\n|00046d5b039c98ccc...|   1514353076|android| -23.49484|-46.630811|        41.35100174|6gyf6fukx|\n|00046d5b039c98ccc...|   1514355879|android|-23.494837|-46.630846|        30.33099937|6gyf6fukw|\n|00046d5b039c98ccc...|   1514352468|android|-23.494836|-46.630767|        47.49399948|6gyf6fus8|\n|00046d5b039c98ccc...|   1514353929|android|-23.494886|-46.630823|        22.77700043|6gyf6fukr|\n+--------------------+-------------+-------+----------+----------+-------------------+---------+\nonly showing top 20 rows\n\n"
        },
        {
          "metadata" : { },
          "data" : {
            "text/html" : ""
          },
          "output_type" : "execute_result",
          "execution_count" : 14,
          "time" : "Took: 5.093s, at 2018-06-19 18:01"
        }
      ]
    },
    {
      "metadata" : {
        "id" : "3CC6166F959645629B51CE8D7AAA378F"
      },
      "cell_type" : "markdown",
      "source" : "With Spark Notebooks, we can use Java/Scala libraries and even our own Java/Scala code. \n\nIn our git repo, you will find a custom library we created for testing. It was compiled and added to the ../data/notebook-repository folder. This folder was mapped in our docker-compose.yml to the .m2 local repository used by Spark notebook. So, since this library is not available on the Maven central repository, we can find the library in the local disk.\n\nWe added our custom library to the Notebook Meta Data and now we can execute our custom code:"
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : false,
        "id" : "CA78720041A7439781EF816F97D7EBA1"
      },
      "cell_type" : "code",
      "source" : [
        "com.tailtarget.sparksqlgeohash.Util.tellTime()"
      ],
      "outputs" : [
        {
          "name" : "stdout",
          "output_type" : "stream",
          "text" : "res23: java.util.Date = Tue Jun 19 18:01:04 UTC 2018\n"
        },
        {
          "metadata" : { },
          "data" : {
            "text/html" : "Tue Jun 19 18:01:04 UTC 2018"
          },
          "output_type" : "execute_result",
          "execution_count" : 15,
          "time" : "Took: 1.776s, at 2018-06-19 18:01"
        }
      ]
    },
    {
      "metadata" : {
        "id" : "41FB178264814A17861FBDDCECE42E6E"
      },
      "cell_type" : "markdown",
      "source" : "We can also register our own functions and use them in our queries. For example, in our sample code we have the following class:\n\n`public class SparkGeoHash implements UDF3<Double, Double, Integer, String> {\n\n    public String call(Double latitude, Double longitude, Integer numberOfCharacters){\n\n        return GeoHash.withCharacterPrecision(latitude, longitude, numberOfCharacters).toBase32();\n    }\n}`\n\nThis code shows how to create a User Defined Function. Our sample function received a latitute and longitude pair and returns the corresponding geohash with the requested number of character.\n\nYou can register a function like this:\n"
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : false,
        "id" : "6DD383728A5F4894998A7917728FD1D4"
      },
      "cell_type" : "code",
      "source" : [
        "import org.apache.spark.sql.functions.udf\n",
        "\n",
        "val geoHash = new com.tailtarget.sparksqlgeohash.udf.SparkGeoHash();\n",
        "spark.udf.register(\"geoHash\", geoHash, DataTypes.StringType);"
      ],
      "outputs" : [
        {
          "name" : "stdout",
          "output_type" : "stream",
          "text" : "import org.apache.spark.sql.functions.udf\ngeoHash: com.tailtarget.sparksqlgeohash.udf.SparkGeoHash = com.tailtarget.sparksqlgeohash.udf.SparkGeoHash@4f7f3d8d\n"
        },
        {
          "metadata" : { },
          "data" : {
            "text/html" : ""
          },
          "output_type" : "execute_result",
          "execution_count" : 16,
          "time" : "Took: 2.682s, at 2018-06-19 18:01"
        }
      ]
    },
    {
      "metadata" : {
        "id" : "0AD264179B644473AC0A915BE900DD42"
      },
      "cell_type" : "markdown",
      "source" : "Now we can use our function in our queries:"
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : false,
        "id" : "648BB8D18A6541318F6DC34030E555BB"
      },
      "cell_type" : "code",
      "source" : [
        "val recordsWithFunction = records\n",
        "      .withColumn(\"generatedGeoHash\", \n",
        "                  callUDF(\"geoHash\", \n",
        "                          col(\"latitude\"), \n",
        "                          col(\"longitude\"), \n",
        "                          lit(12)))\n",
        "      .select(col(\"ad_id\"), \n",
        "              col(\"latitude\"),\n",
        "              col(\"longitude\"),\n",
        "              col(\"geo_hash\"),\n",
        "              col(\"generatedGeoHash\"))\n",
        "\n",
        "recordsWithFunction.show()"
      ],
      "outputs" : [
        {
          "name" : "stdout",
          "output_type" : "stream",
          "text" : "+--------------------+----------+----------+---------+----------------+\n|               ad_id|  latitude| longitude| geo_hash|generatedGeoHash|\n+--------------------+----------+----------+---------+----------------+\n|d8df62d20b0538ded...|-12.879151|-38.407512|7jswwp2t8|    7jswwp2t805r|\n|d8df62d20b0538ded...|-12.879146|-38.407534|7jswwp2mx|    7jswwp2mx94v|\n|7730a7ed3612db924...|-20.729792|-46.609906|6uqf5678n|    6uqf5678nqxn|\n|7730a7ed3612db924...|-20.729728|-46.609985|6uqf5678s|    6uqf5678sds5|\n|7730a7ed3612db924...|-20.729465| -46.61035|6uqf5676h|    6uqf5676h5sh|\n|7730a7ed3612db924...|-20.729464|-46.610304|6uqf5676j|    6uqf5676j5y6|\n|7730a7ed3612db924...|-20.729458|-46.610304|6uqf5676j|    6uqf5676jhyq|\n|7730a7ed3612db924...|-20.729453|-46.610302|6uqf5676j|    6uqf5676jjzu|\n|7730a7ed3612db924...|-20.729444|-46.610221|6uqf5676p|    6uqf5676pps1|\n|7730a7ed3612db924...|-20.729381|-46.610312|6uqf5676t|    6uqf5676t523|\n|7730a7ed3612db924...|-20.728869|-46.610674|6uqf567js|    6uqf567jsddr|\n|7730a7ed3612db924...| -20.72774|-46.600174|6uqf5ddu1|    6uqf5ddu1jpy|\n|7730a7ed3612db924...|-20.727699|-46.600129|6uqf5ddu6|    6uqf5ddu6kc7|\n|7730a7ed3612db924...|-20.727699|-46.600132|6uqf5ddu6|    6uqf5ddu6hz5|\n|7730a7ed3612db924...|-20.727697| -46.60013|6uqf5ddu6|    6uqf5ddu6m0x|\n|7730a7ed3612db924...|-20.727697|-46.600134|6uqf5ddu6|    6uqf5ddu6jjx|\n|7730a7ed3612db924...|-20.727691|-46.600131|6uqf5ddu6|    6uqf5ddu6nrf|\n|7730a7ed3612db924...|-20.727688|-46.600139|6uqf5ddu6|    6uqf5ddu6ncu|\n|7730a7ed3612db924...|-20.727688|-46.600139|6uqf5ddu6|    6uqf5ddu6ncu|\n|7730a7ed3612db924...|-20.727688|-46.600139|6uqf5ddu6|    6uqf5ddu6ncu|\n+--------------------+----------+----------+---------+----------------+\nonly showing top 20 rows\n\nrecordsWithFunction: org.apache.spark.sql.DataFrame = [ad_id: string, latitude: double ... 3 more fields]\n"
        },
        {
          "metadata" : { },
          "data" : {
            "text/html" : ""
          },
          "output_type" : "execute_result",
          "execution_count" : 17,
          "time" : "Took: 3.135s, at 2018-06-19 18:01"
        }
      ]
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : true,
        "id" : "B71F8E0B6DAA41DA9CA87222DFF3796D"
      },
      "cell_type" : "markdown",
      "source" : "You can also register your common functions by code, like this:\n\n`public class Util {\n\n    public static void registerUDFS(SparkSession context) {\n    \tcontext.udf().register(\"geoHash\", new SparkGeoHash(), DataTypes.StringType);\n    }\n`}\n\nAnd then, you call your method:"
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : false,
        "id" : "28DCF5EE7CD7496DA097227A02C50E49"
      },
      "cell_type" : "code",
      "source" : [
        "com.tailtarget.sparksqlgeohash.Util.registerUDFS(spark)\n",
        "\n",
        "val recordsWithFunction = records\n",
        "                       .withColumn(\"generatedGeoHash\", \n",
        "                                   callUDF(\"geoHash\", \n",
        "                                           col(\"latitude\"), \n",
        "                                           col(\"longitude\"), \n",
        "                                           lit(12)))\n",
        "                       .select(col(\"ad_id\"), \n",
        "                               col(\"latitude\"),\n",
        "                               col(\"longitude\"),\n",
        "                               col(\"geo_hash\"),\n",
        "                               col(\"generatedGeoHash\"))\n",
        "\n",
        "recordsWithFunction.show()"
      ],
      "outputs" : [
        {
          "name" : "stdout",
          "output_type" : "stream",
          "text" : "+--------------------+----------+----------+---------+----------------+\n|               ad_id|  latitude| longitude| geo_hash|generatedGeoHash|\n+--------------------+----------+----------+---------+----------------+\n|d8df62d20b0538ded...|-12.879151|-38.407512|7jswwp2t8|    7jswwp2t805r|\n|d8df62d20b0538ded...|-12.879146|-38.407534|7jswwp2mx|    7jswwp2mx94v|\n|7730a7ed3612db924...|-20.729792|-46.609906|6uqf5678n|    6uqf5678nqxn|\n|7730a7ed3612db924...|-20.729728|-46.609985|6uqf5678s|    6uqf5678sds5|\n|7730a7ed3612db924...|-20.729465| -46.61035|6uqf5676h|    6uqf5676h5sh|\n|7730a7ed3612db924...|-20.729464|-46.610304|6uqf5676j|    6uqf5676j5y6|\n|7730a7ed3612db924...|-20.729458|-46.610304|6uqf5676j|    6uqf5676jhyq|\n|7730a7ed3612db924...|-20.729453|-46.610302|6uqf5676j|    6uqf5676jjzu|\n|7730a7ed3612db924...|-20.729444|-46.610221|6uqf5676p|    6uqf5676pps1|\n|7730a7ed3612db924...|-20.729381|-46.610312|6uqf5676t|    6uqf5676t523|\n|7730a7ed3612db924...|-20.728869|-46.610674|6uqf567js|    6uqf567jsddr|\n|7730a7ed3612db924...| -20.72774|-46.600174|6uqf5ddu1|    6uqf5ddu1jpy|\n|7730a7ed3612db924...|-20.727699|-46.600129|6uqf5ddu6|    6uqf5ddu6kc7|\n|7730a7ed3612db924...|-20.727699|-46.600132|6uqf5ddu6|    6uqf5ddu6hz5|\n|7730a7ed3612db924...|-20.727697| -46.60013|6uqf5ddu6|    6uqf5ddu6m0x|\n|7730a7ed3612db924...|-20.727697|-46.600134|6uqf5ddu6|    6uqf5ddu6jjx|\n|7730a7ed3612db924...|-20.727691|-46.600131|6uqf5ddu6|    6uqf5ddu6nrf|\n|7730a7ed3612db924...|-20.727688|-46.600139|6uqf5ddu6|    6uqf5ddu6ncu|\n|7730a7ed3612db924...|-20.727688|-46.600139|6uqf5ddu6|    6uqf5ddu6ncu|\n|7730a7ed3612db924...|-20.727688|-46.600139|6uqf5ddu6|    6uqf5ddu6ncu|\n+--------------------+----------+----------+---------+----------------+\nonly showing top 20 rows\n\nrecordsWithFunction: org.apache.spark.sql.DataFrame = [ad_id: string, latitude: double ... 3 more fields]\n"
        },
        {
          "metadata" : { },
          "data" : {
            "text/html" : ""
          },
          "output_type" : "execute_result",
          "execution_count" : 18,
          "time" : "Took: 5.436s, at 2018-06-19 18:01"
        }
      ]
    },
    {
      "metadata" : {
        "id" : "59A81705A28248EFA68415F92C29433F"
      },
      "cell_type" : "markdown",
      "source" : "Let's count devices by a geohash:"
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : false,
        "id" : "19B6541CB9C644E28DB4525169EC13CD"
      },
      "cell_type" : "code",
      "source" : [
        "val devicesByGeoHash = records\n",
        "                       .withColumn(\"generatedGeoHash\", \n",
        "                                   callUDF(\"geoHash\", \n",
        "                                           col(\"latitude\"), \n",
        "                                           col(\"longitude\"), \n",
        "                                           lit(2)))\n",
        "                       .select(col(\"ad_id\"), \n",
        "                               col(\"generatedGeoHash\"))\n",
        "                       .distinct()\n",
        "                       .groupBy(\"generatedGeoHash\")\n",
        "                       .count()\n",
        "                       .sort(desc(\"count\"))\n",
        "devicesByGeoHash.show()"
      ],
      "outputs" : [
        {
          "name" : "stdout",
          "output_type" : "stream",
          "text" : "+----------------+-----+\n|generatedGeoHash|count|\n+----------------+-----+\n|              6g| 2503|\n|              75|  907|\n|              7h|  813|\n|              7n|  763|\n|              6u|  734|\n|              6v|  515|\n|              7p|  427|\n|              6f|  422|\n|              7j|  385|\n|              6z|  223|\n|              6x|  125|\n|              6y|   91|\n|              6w|   47|\n|              6t|   34|\n|              d8|   31|\n|              db|   23|\n|              6q|   21|\n|              6s|    5|\n|              6r|    4|\n|              6d|    4|\n+----------------+-----+\nonly showing top 20 rows\n\ndevicesByGeoHash: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [generatedGeoHash: string, count: bigint]\n"
        },
        {
          "metadata" : { },
          "data" : {
            "text/html" : ""
          },
          "output_type" : "execute_result",
          "execution_count" : 19,
          "time" : "Took: 19.979s, at 2018-06-19 18:02"
        }
      ]
    },
    {
      "metadata" : {
        "id" : "CC9089174A9A44EAAF902128B55A8506"
      },
      "cell_type" : "markdown",
      "source" : "Ploting results a bar chart:"
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : false,
        "id" : "B0B61E2E2EDD446099543C23A24A1F14"
      },
      "cell_type" : "code",
      "source" : [
        "devicesByGeoHash.createOrReplaceTempView(\"devicesByGeoHash\")\n",
        "\n",
        "BarChart(devicesByGeoHash, fields=Some{(\"generatedGeoHash\", \"count\")})"
      ],
      "outputs" : [
        {
          "name" : "stdout",
          "output_type" : "stream",
          "text" : "res39: notebook.front.widgets.charts.BarChart[org.apache.spark.sql.Dataset[org.apache.spark.sql.Row]] = <BarChart widget>\n"
        },
        {
          "metadata" : { },
          "data" : {
            "text/html" : "<div>\n      <script data-this=\"{&quot;dataId&quot;:&quot;anon67297ce930adff611eabe0d8a6278395&quot;,&quot;dataInit&quot;:[{&quot;generatedGeoHash&quot;:&quot;6g&quot;,&quot;count&quot;:2503},{&quot;generatedGeoHash&quot;:&quot;75&quot;,&quot;count&quot;:907},{&quot;generatedGeoHash&quot;:&quot;7h&quot;,&quot;count&quot;:813},{&quot;generatedGeoHash&quot;:&quot;7n&quot;,&quot;count&quot;:763},{&quot;generatedGeoHash&quot;:&quot;6u&quot;,&quot;count&quot;:734},{&quot;generatedGeoHash&quot;:&quot;6v&quot;,&quot;count&quot;:515},{&quot;generatedGeoHash&quot;:&quot;7p&quot;,&quot;count&quot;:427},{&quot;generatedGeoHash&quot;:&quot;6f&quot;,&quot;count&quot;:422},{&quot;generatedGeoHash&quot;:&quot;7j&quot;,&quot;count&quot;:385},{&quot;generatedGeoHash&quot;:&quot;6z&quot;,&quot;count&quot;:223},{&quot;generatedGeoHash&quot;:&quot;6x&quot;,&quot;count&quot;:125},{&quot;generatedGeoHash&quot;:&quot;6y&quot;,&quot;count&quot;:91},{&quot;generatedGeoHash&quot;:&quot;6w&quot;,&quot;count&quot;:47},{&quot;generatedGeoHash&quot;:&quot;6t&quot;,&quot;count&quot;:34},{&quot;generatedGeoHash&quot;:&quot;d8&quot;,&quot;count&quot;:31},{&quot;generatedGeoHash&quot;:&quot;db&quot;,&quot;count&quot;:23},{&quot;generatedGeoHash&quot;:&quot;6q&quot;,&quot;count&quot;:21},{&quot;generatedGeoHash&quot;:&quot;6s&quot;,&quot;count&quot;:5},{&quot;generatedGeoHash&quot;:&quot;6r&quot;,&quot;count&quot;:4},{&quot;generatedGeoHash&quot;:&quot;6d&quot;,&quot;count&quot;:4},{&quot;generatedGeoHash&quot;:&quot;7r&quot;,&quot;count&quot;:1}],&quot;genId&quot;:&quot;1037237526&quot;}\" type=\"text/x-scoped-javascript\">/*<![CDATA[*/req(['../javascripts/notebook/playground','../javascripts/notebook/magic/barChart'], \n      function(playground, _magicbarChart) {\n        // data ==> data-this (in observable.js's scopedEval) ==> this in JS => { dataId, dataInit, ... }\n        // this ==> scope (in observable.js's scopedEval) ==> this.parentElement ==> div.container below (toHtml)\n\n        playground.call(data,\n                        this\n                        ,\n                        {\n    \"f\": _magicbarChart,\n    \"o\": {\"x\":\"generatedGeoHash\",\"y\":\"count\",\"width\":600,\"height\":400}\n  }\n  \n                        \n                        \n                      );\n      }\n    );/*]]>*/</script>\n    <div>\n      <span class=\"chart-total-item-count\"><p data-bind=\"text: value\"><script data-this=\"{&quot;valueId&quot;:&quot;anon7b2ac1e6ded180cece448c4caa4097d0&quot;,&quot;initialValue&quot;:&quot;21&quot;}\" type=\"text/x-scoped-javascript\">/*<![CDATA[*/\nreq(\n['observable', 'knockout'],\nfunction (O, ko) {\n  ko.applyBindings({\n      value: O.makeObservable(valueId, initialValue)\n    },\n    this\n  );\n});\n        /*]]>*/</script></p> entries total</span>\n      <span class=\"chart-sampling-warning\"><p data-bind=\"text: value\"><script data-this=\"{&quot;valueId&quot;:&quot;anone88101e0080d138a648798826ddab459&quot;,&quot;initialValue&quot;:&quot;&quot;}\" type=\"text/x-scoped-javascript\">/*<![CDATA[*/\nreq(\n['observable', 'knockout'],\nfunction (O, ko) {\n  ko.applyBindings({\n      value: O.makeObservable(valueId, initialValue)\n    },\n    this\n  );\n});\n        /*]]>*/</script></p></span>\n      <div>\n      </div>\n    </div></div>"
          },
          "output_type" : "execute_result",
          "execution_count" : 24,
          "time" : "Took: 15.095s, at 2018-06-19 18:06"
        }
      ]
    },
    {
      "metadata" : {
        "id" : "8CA6B24C6FC14BC187C6A32D8C9BB7DA"
      },
      "cell_type" : "markdown",
      "source" : "Plotting data as a map:"
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : false,
        "id" : "E204F91DAF844B8DBCDFF5858048158C"
      },
      "cell_type" : "code",
      "source" : [
        "records.createOrReplaceTempView(\"records\")\n",
        "\n",
        "val grupedLocation = spark.sql(\n",
        "  \"SELECT first(latitude) as latitude, first(longitude) as longitude, first(geo_hash), first(substring(geo_hash, 0, 2)) \" +  \n",
        "  \"FROM records group by substring(geo_hash, 0, 2)\");\n",
        "\n",
        "GeoPointsChart(grupedLocation,latLonFields=Some{(\"latitude\",\"longitude\")})"
      ],
      "outputs" : [
        {
          "name" : "stdout",
          "output_type" : "stream",
          "text" : "grupedLocation: org.apache.spark.sql.DataFrame = [latitude: double, longitude: double ... 2 more fields]\nres47: notebook.front.widgets.charts.GeoPointsChart[org.apache.spark.sql.DataFrame] = <GeoPointsChart widget>\n"
        },
        {
          "metadata" : { },
          "data" : {
            "text/html" : "<div>\n      <script data-this=\"{&quot;dataId&quot;:&quot;anonf2e355379c6e79991d2487b6ff533718&quot;,&quot;dataInit&quot;:[{&quot;latitude&quot;:-4.226845,&quot;longitude&quot;:-69.936763},{&quot;latitude&quot;:-3.856569,&quot;longitude&quot;:-32.428653},{&quot;latitude&quot;:-4.17382,&quot;longitude&quot;:-38.46061},{&quot;latitude&quot;:-3.1058,&quot;longitude&quot;:-60.012963},{&quot;latitude&quot;:-22.865364,&quot;longitude&quot;:-43.453884},{&quot;latitude&quot;:-19.98267,&quot;longitude&quot;:-44.171425},{&quot;latitude&quot;:-12.879151,&quot;longitude&quot;:-38.407512},{&quot;latitude&quot;:-9.973219,&quot;longitude&quot;:-67.804396},{&quot;latitude&quot;:-6.099627,&quot;longitude&quot;:-49.601069},{&quot;latitude&quot;:0.01924,&quot;longitude&quot;:-51.087177},{&quot;latitude&quot;:-20.729792,&quot;longitude&quot;:-46.609906},{&quot;latitude&quot;:-9.657434,&quot;longitude&quot;:-35.7103},{&quot;latitude&quot;:-13.64153,&quot;longitude&quot;:-57.913542},{&quot;latitude&quot;:-23.555076,&quot;longitude&quot;:-46.95946},{&quot;latitude&quot;:-29.759479,&quot;longitude&quot;:-57.086191},{&quot;latitude&quot;:-20.260931,&quot;longitude&quot;:-56.380494},{&quot;latitude&quot;:-10.759203,&quot;longitude&quot;:-65.30369},{&quot;latitude&quot;:-1.279749,&quot;longitude&quot;:-47.939325},{&quot;latitude&quot;:2.803452,&quot;longitude&quot;:-60.761602},{&quot;latitude&quot;:-16.755429,&quot;longitude&quot;:-49.266363},{&quot;latitude&quot;:-31.802535,&quot;longitude&quot;:-54.028392}],&quot;genId&quot;:&quot;2119401573&quot;}\" type=\"text/x-scoped-javascript\">/*<![CDATA[*/req(['../javascripts/notebook/playground','../javascripts/notebook/magic/geoPointsChart'], \n      function(playground, _magicgeoPointsChart) {\n        // data ==> data-this (in observable.js's scopedEval) ==> this in JS => { dataId, dataInit, ... }\n        // this ==> scope (in observable.js's scopedEval) ==> this.parentElement ==> div.container below (toHtml)\n\n        playground.call(data,\n                        this\n                        ,\n                        {\n    \"f\": _magicgeoPointsChart,\n    \"o\": {\"lat\":\"latitude\",\"lon\":\"longitude\",\"width\":600,\"height\":400,\"rField\":null,\"colorField\":null}\n  }\n  \n                        \n                        \n                      );\n      }\n    );/*]]>*/</script>\n    <div>\n      <span class=\"chart-total-item-count\"><p data-bind=\"text: value\"><script data-this=\"{&quot;valueId&quot;:&quot;anon072ba8317a3ae64a8d99043e03de9b06&quot;,&quot;initialValue&quot;:&quot;21&quot;}\" type=\"text/x-scoped-javascript\">/*<![CDATA[*/\nreq(\n['observable', 'knockout'],\nfunction (O, ko) {\n  ko.applyBindings({\n      value: O.makeObservable(valueId, initialValue)\n    },\n    this\n  );\n});\n        /*]]>*/</script></p> entries total</span>\n      <span class=\"chart-sampling-warning\"><p data-bind=\"text: value\"><script data-this=\"{&quot;valueId&quot;:&quot;anon19d594d728849e3c8863df8a9dda135f&quot;,&quot;initialValue&quot;:&quot;&quot;}\" type=\"text/x-scoped-javascript\">/*<![CDATA[*/\nreq(\n['observable', 'knockout'],\nfunction (O, ko) {\n  ko.applyBindings({\n      value: O.makeObservable(valueId, initialValue)\n    },\n    this\n  );\n});\n        /*]]>*/</script></p></span>\n      <div>\n      </div>\n    </div></div>"
          },
          "output_type" : "execute_result",
          "execution_count" : 28,
          "time" : "Took: 6.701s, at 2018-06-19 18:08"
        }
      ]
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : true,
        "id" : "D23BBEE959514EFFB7F5AE4109AEB3F2"
      },
      "cell_type" : "markdown",
      "source" : "To improve performance, you can persist temporary results. Compare the time to compute the following two equivalent code snippets:"
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : false,
        "id" : "C25A546405684B2D88BCC87DFB2DA45E"
      },
      "cell_type" : "code",
      "source" : [
        "\n",
        "val devicesByGeoHash = records\n",
        "                       .withColumn(\"generatedGeoHash\", \n",
        "                                   callUDF(\"geoHash\", col(\"latitude\"), col(\"longitude\"), lit(2)))\n",
        "                       .select(col(\"ad_id\"), \n",
        "                               col(\"generatedGeoHash\"))\n",
        "                       .distinct().groupBy(\"generatedGeoHash\").count().sort(desc(\"count\"))\n",
        "\n",
        "val moreThan1000 = devicesByGeoHash.filter($\"count\" > 1000).count();\n",
        "val between500And1000 = devicesByGeoHash.filter($\"count\" > 500 && $\"count\" < 1000).count();\n",
        "val lessThan500 = devicesByGeoHash.filter($\"count\" < 500).count();\n"
      ],
      "outputs" : [
        {
          "name" : "stdout",
          "output_type" : "stream",
          "text" : "devicesByGeoHash: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [generatedGeoHash: string, count: bigint]\nmoreThan1000: Long = 1\nbetween500And1000: Long = 5\nlessThan500: Long = 15\n"
        },
        {
          "metadata" : { },
          "data" : {
            "text/html" : ""
          },
          "output_type" : "execute_result",
          "execution_count" : 21,
          "time" : "Took: 51.831s, at 2018-06-19 18:06"
        }
      ]
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : false,
        "id" : "99C8C6EBC06A44078BFA743D744BDA83"
      },
      "cell_type" : "code",
      "source" : [
        "val devicesByGeoHash = records\n",
        "                       .withColumn(\"generatedGeoHash\", \n",
        "                                   callUDF(\"geoHash\", col(\"latitude\"), col(\"longitude\"), lit(2)))\n",
        "                       .select(col(\"ad_id\"), \n",
        "                               col(\"generatedGeoHash\"))\n",
        "                       .distinct().groupBy(\"generatedGeoHash\").count().sort(desc(\"count\"))\n",
        "\n",
        "val persisted = devicesByGeoHash.persist(org.apache.spark.storage.StorageLevel.MEMORY_AND_DISK)\n",
        "\n",
        "val moreThan1000 = persisted.filter($\"count\" > 1000).count();\n",
        "val between500And1000 = persisted.filter($\"count\" > 500 && $\"count\" < 1000).count();\n",
        "val lessThan500 = persisted.filter($\"count\" < 500).count();\n",
        "\n",
        "persisted.unpersist()"
      ],
      "outputs" : [
        {
          "name" : "stdout",
          "output_type" : "stream",
          "text" : "devicesByGeoHash: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [generatedGeoHash: string, count: bigint]\npersisted: devicesByGeoHash.type = [generatedGeoHash: string, count: bigint]\nmoreThan1000: Long = 1\nbetween500And1000: Long = 5\nlessThan500: Long = 15\nres35: persisted.type = [generatedGeoHash: string, count: bigint]\n"
        },
        {
          "metadata" : { },
          "data" : {
            "text/html" : "<div class=\"df-canvas\">\n      <script data-this=\"{&quot;dataId&quot;:&quot;anonf37cce207ecc51eb3b01f2710013e3ec&quot;,&quot;partitionIndexId&quot;:&quot;anon8c6f04e7cfb8a191ff7a50d9a0ec15ec&quot;,&quot;numPartitions&quot;:1,&quot;dfSchema&quot;:{&quot;type&quot;:&quot;struct&quot;,&quot;fields&quot;:[{&quot;name&quot;:&quot;generatedGeoHash&quot;,&quot;type&quot;:&quot;string&quot;,&quot;nullable&quot;:true,&quot;metadata&quot;:{}},{&quot;name&quot;:&quot;count&quot;,&quot;type&quot;:&quot;long&quot;,&quot;nullable&quot;:false,&quot;metadata&quot;:{}}]}}\" type=\"text/x-scoped-javascript\">/*<![CDATA[*/req(['../javascripts/notebook/dataframe','../javascripts/notebook/consoleDir'], \n      function(dataframe, extension) {\n        dataframe.call(data, this, extension);\n      }\n    );/*]]>*/</script>\n      <link rel=\"stylesheet\" href=\"/assets/stylesheets/ipython/css/dataframe.css\" type=\"text/css\"/>\n    </div>"
          },
          "output_type" : "execute_result",
          "execution_count" : 22,
          "time" : "Took: 26.369s, at 2018-06-19 18:06"
        }
      ]
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : true,
        "id" : "E43214586FF94EA6B308DF62A9B3E33C"
      },
      "cell_type" : "code",
      "source" : [
        ""
      ],
      "outputs" : [ ]
    }
  ],
  "nbformat" : 4
}